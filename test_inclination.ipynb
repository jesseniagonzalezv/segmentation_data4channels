{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2606,) (652,) (357,)\n",
      "357\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 395200 into shape (6,512,512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b650a3c71469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mfind_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_file_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mname_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DeepLabV3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'100'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'512'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'512'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mname_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'images_inclination'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/segmentation_mapping/metrics_prediction_2.py\u001b[0m in \u001b[0;36mfind_metrics\u001b[0;34m(train_file_names, val_file_names, test_file_names, channels, max_values, mean_values, std_values, model, fold_out, fold_in, name_model, epochs, out_file, dataset_file, name_file)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mresult_jaccard_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgonzalez/anaconda3/envs/pytorch_clone/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgonzalez/anaconda3/envs/pytorch_clone/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/segmentation_mapping/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_file_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;31m#print(self.mode)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/segmentation_mapping/dataset.py\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(path, channels)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#in CH, H,W  out: H,W,CH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m  \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgonzalez/anaconda3/envs/pytorch_clone/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 447\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgonzalez/anaconda3/envs/pytorch_clone/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 395200 into shape (6,512,512)"
     ]
    }
   ],
   "source": [
    "import glob  ###\n",
    "import os\n",
    "from scalarmeanstd import meanstd\n",
    "from models import UNet11,UNet\n",
    "from deeplabv3 import deeplabv3_resnet101\n",
    "from fcn import fcn_resnet101\n",
    "import torch\n",
    "from metrics_prediction_2 import find_metrics\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "#data_path= Path('dataset') \n",
    "data_path= Path('/home/gjimenez/AI-PUCP/dataset') # Dataset for experiments\n",
    "#data_path= Path('/home/jrengifo/segmentation_mapping/dataset') \n",
    "\n",
    "data_all='data_512'\n",
    "channels=3\n",
    "\n",
    "train_file_names= np.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/train_files_100_percent_512_DeepLabV3_fold0_0.npy')\n",
    "val_file_names=np.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/val_files_100_percent_512_DeepLabV3_fold0_0.npy')\n",
    "#test_file_names=np.array(sorted(glob.glob(str(data_path/'test_inclination'/'images')+ \"/*.npy\")))\n",
    "test_file_names=np.array(sorted(glob.glob(str(data_path/'test_512'/'images')+ \"/*.npy\")))\n",
    "\n",
    "print(train_file_names.shape,val_file_names.shape,test_file_names.shape)\n",
    "\n",
    "#max_values, mean_values, std_values=meanstd(train_file_names, val_file_names,test_file_names,str(data_path/data_all),channels) #_60 \n",
    "max_values = 255\n",
    "mean_values = [0.485, 0.456, 0.406]\n",
    "std_values = [0.229, 0.224, 0.225]\n",
    "    \n",
    "num_classes = 3\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = deeplabv3_resnet101(num_classes=num_classes, input_channels=channels)\n",
    "model = deeplabv3_resnet101(pretrained=False, progress=True, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/model_100_percent_512_DeepLabV3_foldout0_foldin0_100epochs'))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "find_metrics(train_file_names,val_file_names, test_file_names, channels,max_values, mean_values, std_values,model,fold_out='0', fold_in='0',  name_model='DeepLabV3', epochs='100',out_file='512',dataset_file='512' ,name_file='images_inclination' )  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagenes inclinadas + Diferentes modelos ubicadas es dataset/test_inclination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2606,) (652,) (154,)\n",
      "154\n",
      "train_512\n",
      "Dice =  0.8608219488338065 0.13360118433587692\n",
      "Dice classes=  [0.85423   0.8703933 0.8578423]\n",
      "Jaccard =  0.8048222409875767 0.15797226270254755\n",
      "Jaccard classes=  [0.7814807  0.80982983 0.8231572 ] \n",
      "\n",
      "val_512\n",
      "Dice =  0.819973485464333 0.16243895753345242\n",
      "Dice classes=  [0.8339342  0.82707757 0.7989082 ]\n",
      "Jaccard =  0.7578195470322403 0.1902945284647238\n",
      "Jaccard classes=  [0.7511346 0.7608123 0.761512 ] \n",
      "\n",
      "test_512\n",
      "Dice =  0.7298004744308335 0.13262868173745637\n",
      "Dice classes=  [0.6544872  0.8676747  0.66723925]\n",
      "Jaccard =  0.6213699578271283 0.14236213764122263\n",
      "Jaccard classes=  [0.49430734 0.7708394  0.5989631 ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob  ###\n",
    "import os\n",
    "from scalarmeanstd import meanstd\n",
    "from models import UNet11,UNet\n",
    "from deeplabv3 import deeplabv3_resnet101\n",
    "from fcn import fcn_resnet101\n",
    "import torch\n",
    "from metrics_prediction_2 import find_metrics\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "#data_path= Path('dataset')\n",
    "data_path= Path('/home/gjimenez/AI-PUCP/dataset') #Dataset for experiments\n",
    "#data_path= Path('/home/jrengifo/segmentation_mapping/dataset') \n",
    "\n",
    "data_all='data_512'\n",
    "channels=3\n",
    "\n",
    "train_file_names= np.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/train_files_100_percent_512_DeepLabV3_fold0_0.npy')\n",
    "val_file_names=np.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/val_files_100_percent_512_DeepLabV3_fold0_0.npy')\n",
    "test_file_names=np.array(sorted(glob.glob(str(data_path/'test_inclination'/'images')+ \"/*.npy\")))\n",
    "#test_file_names=np.array(sorted(glob.glob(str(data_path/'test_512'/'images')+ \"/*.npy\")))\n",
    "\n",
    "print(train_file_names.shape,val_file_names.shape,test_file_names.shape)\n",
    "\n",
    "max_values = 255\n",
    "mean_values = [0.485, 0.456, 0.406]\n",
    "std_values = [0.229, 0.224, 0.225]\n",
    "    \n",
    "num_classes = 3\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = deeplabv3_resnet101(num_classes=num_classes, input_channels=channels)\n",
    "model = deeplabv3_resnet101(pretrained=False, progress=True, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/model_100_percent_512_DeepLabV3_foldout0_foldin0_100epochs'))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "find_metrics(train_file_names,val_file_names, test_file_names, channels,max_values, mean_values, std_values,model,fold_out='0', fold_in='0',  name_model='DeepLabV3', epochs='100',out_file='512',dataset_file='512' ,name_file='images_inclination' )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2606,) (652,) (154,)\n",
      "154\n",
      "train_512\n",
      "Dice =  0.8546368269357507 0.1387055598286146\n",
      "Dice classes=  [0.8542923  0.8650798  0.84453875]\n",
      "Jaccard =  0.7969246723114198 0.16435488544016572\n",
      "Jaccard classes=  [0.78063667 0.8022609  0.80787605] \n",
      "\n",
      "val_512\n",
      "Dice =  0.8251328626714165 0.15917617848727295\n",
      "Dice classes=  [0.83858347 0.8361913  0.8006236 ]\n",
      "Jaccard =  0.7630891665865356 0.18865071899946556\n",
      "Jaccard classes=  [0.75681025 0.7701476  0.76231015] \n",
      "\n",
      "test_512\n",
      "Dice =  0.7338020022619854 0.1339148351597968\n",
      "Dice classes=  [0.66452056 0.86957157 0.66731393]\n",
      "Jaccard =  0.6269430123366319 0.14425160438827803\n",
      "Jaccard classes=  [0.5063792 0.7746299 0.5998199] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob  ###\n",
    "import os\n",
    "from scalarmeanstd import meanstd\n",
    "from models import UNet11,UNet\n",
    "from deeplabv3 import deeplabv3_resnet101\n",
    "from fcn import fcn_resnet101\n",
    "import torch\n",
    "from metrics_prediction_2 import find_metrics\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "#data_path= Path('dataset') \n",
    "data_path= Path('/home/gjimenez/AI-PUCP/dataset') #Dataset for experiments\n",
    "data_all='data_512'\n",
    "channels=3\n",
    "\n",
    "train_file_names= np.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/train_files_100_percent_512_FCN_fold0_0.npy')\n",
    "val_file_names=np.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/val_files_100_percent_512_FCN_fold0_0.npy')\n",
    "test_file_names=np.array(sorted(glob.glob(str(data_path/'test_inclination'/'images')+ \"/*.npy\")))\n",
    "print(train_file_names.shape,val_file_names.shape,test_file_names.shape)\n",
    "\n",
    "mean_values = [0.485, 0.456, 0.406]\n",
    "std_values = [0.229, 0.224, 0.225]\n",
    "\n",
    "num_classes = 3\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = fcn_resnet101(num_classes=num_classes, input_channels=channels)\n",
    "model = fcn_resnet101(pretrained=False, progress=True, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/model_100_percent_512_FCN_foldout0_foldin0_100epochs'))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "find_metrics(train_file_names,val_file_names, test_file_names, channels,max_values, mean_values, std_values,model,fold_out='0', fold_in='0',  name_model='FCN', epochs='100',out_file='512',dataset_file='512' ,name_file='images_inclination' )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154,) (154,) (154,)\n",
      "154\n",
      "train_512\n",
      "Dice =  0.13643984322424058 0.16383154214109055\n",
      "Dice classes=  [1.6196982e-05 6.1934643e-06 4.0929723e-01]\n",
      "Jaccard =  0.13636362823573026 0.16388868457074482\n",
      "Jaccard classes=  [0.        0.        0.4090909] \n",
      "\n",
      "val_512\n",
      "Dice =  0.13643984322424058 0.16383154214109055\n",
      "Dice classes=  [1.6196982e-05 6.1934643e-06 4.0929714e-01]\n",
      "Jaccard =  0.13636362823573026 0.16388868457074482\n",
      "Jaccard classes=  [0.        0.        0.4090909] \n",
      "\n",
      "test_512\n",
      "Dice =  0.13643984322424058 0.16383154214109055\n",
      "Dice classes=  [1.6196982e-05 6.1934643e-06 4.0929714e-01]\n",
      "Jaccard =  0.13636362823573026 0.16388868457074482\n",
      "Jaccard classes=  [0.        0.        0.4090909] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob  ###\n",
    "import os\n",
    "from scalarmeanstd import meanstd\n",
    "from models import UNet11,UNet\n",
    "from deeplabv3 import deeplabv3_resnet101\n",
    "from fcn import fcn_resnet101\n",
    "import torch\n",
    "from metrics_prediction_2 import find_metrics\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "#data_path= Path('dataset') \n",
    "data_path= Path('/home/gjimenez/AI-PUCP/dataset') #Dataset for experiments\n",
    "data_all='data_512'\n",
    "channels=3\n",
    "\n",
    "#train_file_names= np.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/train_files_100_percent_512_UNet_fold0_0.npy')\n",
    "#val_file_names=np.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/val_files_100_percent_512_UNet_fold0_0.npy')\n",
    "train_file_names=np.array(sorted(glob.glob(str(data_path/'test_inclination'/'images')+ \"/*.npy\")))\n",
    "val_file_names=np.array(sorted(glob.glob(str(data_path/'test_inclination'/'images')+ \"/*.npy\")))\n",
    "test_file_names=np.array(sorted(glob.glob(str(data_path/'test_inclination'/'images')+ \"/*.npy\")))\n",
    "\n",
    "print(train_file_names.shape,val_file_names.shape,test_file_names.shape)\n",
    "mean_values = [0.485, 0.456, 0.406]\n",
    "std_values = [0.229, 0.224, 0.225]\n",
    "\n",
    "num_classes = 3\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(num_classes=num_classes, input_channels=channels)\n",
    "model.load_state_dict(torch.load('/home/jrengifo/segmentation_mapping/logs/mapping/512/model_100_percent_512_UNet_foldout0_foldin0_100epochs'))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "find_metrics(train_file_names,val_file_names, test_file_names, channels,max_values, mean_values, std_values,model,fold_out='0', fold_in='0',  name_model='UNet', epochs='100',out_file='512',dataset_file='512' ,name_file='images_inclination' )  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
